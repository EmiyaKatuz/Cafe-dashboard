{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0ace3e",
   "metadata": {},
   "source": [
    "# Cafe Feedback Exploration & Walkthrough\n",
    "\n",
    "This notebook captures the thinking, data processing steps, and exploratory visuals that underpin the Streamlit dashboard. It consolidates the short walkthrough, an explanation of the process, and a quick description of data cleaning so the dashboard can stay focused on the AI analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971bd9f",
   "metadata": {},
   "source": [
    "## Walkthrough & Process\n",
    "- **Goal**: surface hard (ratings, spend) and soft (comments) signals for cafe locations, and deliver actionable insights.\n",
    "- **Steps taken**: inspect raw schema → normalise `Location` strings → parse/clean ratings and currency → coerce timestamps → derive calendar fields → profile distributions for each column → build visuals.\n",
    "- **Why this matters**: the raw file contains stray spaces in locations and timestamp-like strings in `Transaction Value`; without cleaning, filters and spend averages become misleading. Keeping cleaning documented here keeps the dashboard uncluttered.\n",
    "- **How to refresh**: rerun this notebook on new drops; cleaned outputs and charts will stay in sync with the app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e26c5",
   "metadata": {},
   "source": [
    "## Quick explanation of data processing\n",
    "- Drop empty `Unnamed` columns; coerce `Rating` to numeric.\n",
    "- Strip/collapse whitespace in `Location` to merge duplicates (e.g., `Albany ` → `Albany`).\n",
    "- Parse `Transaction Value` as currency, strip `$`/commas, and discard impossible spends (≤0 or >$500) to remove timestamp artefacts.\n",
    "- Parse `Transaction Date and Time` as day-first datetime; derive `Date` and `DayName` for trend views.\n",
    "- Persist these steps so dashboard filters and aggregates stay realistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d700df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "DATA_FILE = Path(\"Sample data - Cafe - Sample data 2400 records.csv\")\n",
    "raw_df = pd.read_csv(DATA_FILE)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daedfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning helpers (mirrors dashboard logic)\n",
    "def parse_transaction(val):\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    s = str(val).strip()\n",
    "    m = re.search(r\"-?\\$?\\s*([0-9]{1,3}(?:,[0-9]{3})*|[0-9]+)(?:\\.[0-9]{1,2})?\", s)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        v = float(re.sub(r\"[,$]\", \"\", m.group()))\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if v <= 0 or v > 500:\n",
    "        return None\n",
    "    return v\n",
    "\n",
    "df = raw_df.copy()\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "df[\"Location\"] = df[\"Location\"].astype(str).str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n",
    "df[\"Rating\"] = pd.to_numeric(df[\"Rating\"], errors=\"coerce\")\n",
    "df[\"Transaction Value\"] = df[\"Transaction Value\"].apply(parse_transaction)\n",
    "df[\"Transaction Date and Time\"] = pd.to_datetime(df[\"Transaction Date and Time\"], dayfirst=True, errors=\"coerce\")\n",
    "df[\"Date\"] = df[\"Transaction Date and Time\"].dt.date\n",
    "df[\"DayName\"] = df[\"Transaction Date and Time\"].dt.day_name()\n",
    "df.dropna(subset=[\"Rating\", \"Transaction Value\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64293b7",
   "metadata": {},
   "source": [
    "## Categorical distributions (all categories printed)\n",
    "For each categorical-like column, the full value counts are displayed. Plots are shown when the category count is manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4304c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = []\n",
    "numeric_cols = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        numeric_cols.append(col)\n",
    "    elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "        categorical_cols.append(col)\n",
    "    else:\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n==== {col} (categorical-like) ====\")\n",
    "    vc = df[col].fillna(\"<missing>\").value_counts()\n",
    "    display(vc)\n",
    "    if 1 < len(vc) <= 30:\n",
    "        vc.sort_values().plot(kind=\"barh\", title=f\"{col} frequency\", figsize=(8, max(4, len(vc) * 0.25)))\n",
    "        plt.xlabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb84f01",
   "metadata": {},
   "source": [
    "## Numeric distributions\n",
    "Descriptive stats and histograms for each numeric-like column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36495a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_cols:\n",
    "    print(f\"\\n==== {col} (numeric-like) ====\")\n",
    "    series = df[col].dropna()\n",
    "    display(series.describe())\n",
    "    series.plot(kind=\"hist\", bins=20, title=f\"{col} histogram\", figsize=(6,4))\n",
    "    plt.xlabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9232ae",
   "metadata": {},
   "source": [
    "## Targeted visuals\n",
    "- Rating distribution and average transaction by rating\n",
    "- Daily trends of rating and spend (to mirror the dashboard)\n",
    "- Top comment keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c3f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts = df[\"Rating\"].value_counts().sort_index()\n",
    "rating_counts.plot(kind=\"bar\", title=\"Rating distribution\", ylabel=\"Count\", xlabel=\"Rating\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "avg_txn_by_rating = df.groupby(\"Rating\")[\"Transaction Value\"].mean()\n",
    "avg_txn_by_rating.plot(kind=\"bar\", title=\"Avg transaction by rating\", ylabel=\"$\", xlabel=\"Rating\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "daily = (\n",
    "    df.groupby(\"Date\")\n",
    "    .agg(avg_rating=(\"Rating\", \"mean\"), avg_txn=(\"Transaction Value\", \"mean\"))\n",
    "    .sort_index()\n",
    ")\n",
    "daily.plot(y=[\"avg_rating\", \"avg_txn\"], title=\"Daily trends: rating and spend\", marker=\"o\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "stop_words = {\"the\",\"and\",\"to\",\"of\",\"a\",\"in\",\"for\",\"with\",\"is\",\"it\",\"on\",\"my\",\"our\",\"at\",\"are\",\"was\",\"be\",\"have\",\"has\",\"that\",\"they\",\"this\",\"i\",\"we\",\"you\",\"their\",\"as\",\"so\",\"its\",\"by\",\"from\",\"an\",\"were\",\"your\",\"also\",\"us\",\"had\"}\n",
    "word_counts = {}\n",
    "for c in df[\"Comment\"].dropna().astype(str):\n",
    "    for w in re.findall(r\"[a-zA-Z']+\", c.lower()):\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            word_counts[w] = word_counts.get(w, 0) + 1\n",
    "top_words = sorted(word_counts.items(), key=lambda kv: kv[1], reverse=True)[:12]\n",
    "pd.DataFrame(top_words, columns=[\"word\", \"count\"]).set_index(\"word\").plot(kind=\"bar\", title=\"Top words in comments\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4294a",
   "metadata": {},
   "source": [
    "## Key takeaways\n",
    "- Location labels need normalisation; otherwise filters show duplicates.\n",
    "- Cleaning transaction values removes timestamp artefacts and keeps spend realistic (~$15 median).\n",
    "- Ratings skew high (4–5) while low ratings are scarce; focus on consistency and speed where comments flag issues.\n",
    "- Daily trend views help spot emerging changes faster than monthly rolls."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
